services:
  zookeeper:
    image: bitnami/zookeeper:3.9.3
    container_name: zookeeper
    volumes:
     - "zookeeper_data:/bitnami/zookeeper"
    ports:
     - "2181:2181"
    networks:
      - sb
    environment:
      ALLOW_ANONYMOUS_LOGIN: yes
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: bitnami/kafka:3.1.0
    container_name: kafka
    hostname: kafka
    ports:
     - "9094:9094"
    networks:
      - sb
    depends_on:
      - zookeeper
    volumes:
     - "kafka_data:/bitnami/kafka"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENERS: INTERNAL://kafka:9092,OUTSIDE://kafka:9094
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,OUTSIDE://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      ALLOW_PLAINTEXT_LISTENER: yes
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_CREATE_TOPICS: "$(sed 's/:[^,]*/:1:1/g' <<< $TOPICS_DATA),${TSink}:1:1"
      KAFKA_LOG_RETENTION_HOURS: 1
      KAFKA_LOG_RETENTION_BYTES: 4073741824
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_RETENTION_CHECK_INTERVAL_MS: 300000
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions.sh --bootstrap-server kafka:9092 | grep -q 'kafka'"]
      interval: 10s
      timeout: 5s
      retries: 20

  flink-jobmanager:
    image: shlapique/flink-python
    build:
      context: ./flink
    container_name: flink-jobmanager
    ports:
      - "8081:8081"
    command: jobmanager
    environment:
      JOB_MANAGER_RPC_ADDRESS: flink-jobmanager
    volumes:
      - ./flink/jobs/:/jobs/
    networks:
      - sb

  flink-taskmanager:
    image: shlapique/flink-python
    build:
      context: ./flink
    command: taskmanager
    scale: ${FLINK_SCALE}
    environment:
      JOB_MANAGER_RPC_ADDRESS: flink-jobmanager
    depends_on:
      - flink-jobmanager
    networks:
      - sb

  producer:
    image: shlapique/pyproducer4kafka
    build:
      context: ./producers
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - "shared-state:/shared-state"
      - ./input-data/:/input-data/
      - ./producers/:/app/
    environment:
      PRODUCER: "${PRODUCER}"
      TOPIC_DATA: "${TOPICS_DATA}"
      TOPICS_NUM: ${TOPICS_NUM}
    deploy:
      replicas: ${TOPICS_NUM}
    networks:
      - sb
    entrypoint: ["/app/entrypoint.sh"]

  clickhouse-server:
    image: clickhouse/clickhouse-server:24.12
    container_name: clickhouse-server
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    ports:
      - "8002:9000"
      - "9123:8123"
    volumes:
      - "clickhouse_data:/var/lib/clickhouse"
      - "clickhouse_logs:/var/log/clickhouse-server"
      - ./clickhouse/init.sql:/docker-entrypoint-initdb.d/init.sql
    cap_add:
      - SYS_NICE
      - NET_ADMIN
      - IPC_LOCK
      - SYS_PTRACE
    environment:
      CLICKHOUSE_USER: "${CLICKHOUSE_USER}"
      CLICKHOUSE_PASSWORD: "${CLICKHOUSE_PASSWORD}"

    networks:
      - sb

  heatmap-app:
    image: shlapique/heater
    build:
      context: ./heater
    ports:
      - "8501:8501"
    depends_on:
      - clickhouse-server
    volumes:
      - ./heater/:/app/
    environment:
      APP: "${APP}"
      CLICKHOUSE_USER: "${CLICKHOUSE_USER}"
      CLICKHOUSE_PASSWORD: "${CLICKHOUSE_PASSWORD}"
      CLICKHOUSE_HOST: "${CLICKHOUSE_HOST}"
      CLICKHOUSE_PORT: "${CLICKHOUSE_PORT}"
      CLICKHOUSE_SOURCE_TABLE: "${CLICKHOUSE_SOURCE_TABLE}"

    networks:
      - sb
    entrypoint: ["/app/entrypoint.sh"]


networks:
  sb:
    driver: bridge

volumes:
  zookeeper_data:
    driver: local
  kafka_data:
    driver: local
  shared-state:
    driver: local
  clickhouse_data:
    driver: local
  clickhouse_logs:
    driver: local
